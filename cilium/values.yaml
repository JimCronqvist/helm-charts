cilium:
  podLabels:
    tags.datadoghq.com/service: cilium

  policyEnforcementMode: "default"
  k8sNetworkPolicy:
    # Warning: If set to 'false', this will disable all K8s network policies in the cluster.
    # Useful to make first time installs less risky/error-prone.
    enabled: true

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: eks.amazonaws.com/compute-type
                operator: NotIn
                values:
                  - fargate

  # If you only need L3/L4 policies, you can set this to false in order to disable L7 proxying. DNS content rules will still function.
  l7Proxy: false
  envoy:
    # Set to true if you want a separate DaemonSet for envoy container instead of using the cilium agent as the L7 proxy.
    enabled: false
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: cilium.io/no-schedule
                  operator: NotIn
                  values:
                    - "true"
                - key: eks.amazonaws.com/compute-type
                  operator: NotIn
                  values:
                    - fargate

  hubble:
    enabled: true
    relay:
      enabled: true
    ui:
      enabled: true

  #
  # Below are a few pre-configured options for Cilium, ensure that you only have one section active at any given time.
  #

  # Option 1 - EKS with CNI chaining mode (AWS VPC CNI + Cilium) - Good choice if you only need Cilium for network policies and to support fqdn egress policies.
  # After install, all pods needs to be restarted to take effect, see: https://docs.cilium.io/en/latest/installation/cni-chaining-aws-cni/#restart-existing-pods
  # Install by:
  # helm upgrade --install cilium oci://ghcr.io/jimcronqvist/helm-charts/cilium -n kube-system \
  #  --set cilium.cni.chainingMode=aws-cni \
  #  --set cilium.cni.exclusive=false \
  #  --set cilium.enableIPv4Masquerade=false \
  #  --set cilium.routingMode=native
  #
  # cni:
  #   chainingMode: aws-cni
  #   exclusive: false
  # enableIPv4Masquerade: false
  # routingMode: native

  # Option 2 - EKS full mode - Note: This requires further steps to enable Cilium as the default CNI, please check the docs.
  # eni:
  #   enabled: true
  # ipam:
  #   mode: eni
  # routingMode: native

  # Option 3 - K3s with Cilium as the default CNI
  # Note: When installing k3s, ensure to do it with these configs: --flannel-backend=none --disable-network-policy
  # Install by:
  # helm upgrade --install cilium oci://ghcr.io/jimcronqvist/helm-charts/cilium -n kube-system \
  #  --set cilium.ipam.operator.clusterPoolIPv4PodCIDRList="10.42.0.0/16" \
  #  --set cilium.operator.replicas=1
  #
  # ipam:
  #   operator:
  #     clusterPoolIPv4PodCIDRList: "10.42.0.0/16" # replicates the default k3s CIDR
  # operator:
  #   replicas: 1
